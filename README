How to run our project
1. Ensure you have downloaded OLLAMA and loaded the deepcoder:1.5B model.
2. Ensure the 'dump.rdb' file is present in the main-app folder.
3. Run the following commands on three different terminals of your choice:
On the first terminal, change directory to 'main-app' and run the 'redis-server' command. Ensure the server is initialized and wait until Redis has finished loading RDB.
On the second terminal, run the 'ollama serve' command to start ollama.
On the third terminal, run './script.sh'. The command may take a while to run as we run comprehensive unit tests for each framework. In the end, our program will print out common Issues from `IssueList1` and `IssueList2`.

Some notes:
For some reason we get an empty result when ollama runs too much, perhaps ollama saves our 



LLMService Microservice Evaluation Results
Microservice A calls the LLMService and provides the OLLAMA model with the issue body. Next, Microservice B calls the LLMService and provides '.c' files in the specified 'selected_repo.dat'. Lastly, Microservice C calls the LLM service and compares both `IssueList1` and `IssueList2`.
The result from microservice A and B contains good formatting of fields (bug_type, line, description, filename) but often contain hallucinations (gibberish output), which result in our Main-app to frequently returns an empty array ([]) because the model cannot extract descriptions to compare bugs at microservice C. 
However, in the RARE cases where the model does produce valid outputs, we include a sample output shown below:

```json
[
  {
    "bug_type": "missing_kerberos_protocol",
    "line": "40",
    "description": "The curl command failed to establish a gss_init_sec_context() because an unsupported mechanism was requested. unknown mech-code 0 for mech unknown.",
    "filename": "https://github.com/curl/curl/commit/0a5ea09a910e7883fd7a1c333e8a36fc782fe537"
  },
  {
    "bug_type": "defect_included_file",
    "line": "1",
    "description": "The included file does not contain the expected data.",
    "filename": "lib(connect.c)"
  }
]
[
  {
    "bug_type": "missing_kerberos_protocol",
    "line": "40",
    "description": "The curl command failed to establish a gss_init_sec_context() because an unsupported mechanism was requested. unknown mech-code 0 for mech unknown.",
    "filename": "https://github.com/curl/curl/commit/0a5ea09a910e7883fd7a1c333e8a36fc782fe537"
  },
  {
    "bug_type": "defect_included_file",
    "line": "1",
    "description": "The included file does not contain the expected data.",
    "filename": "lib(connect.c)"
  }
]
```

Based on the output, the model appears to follow the required fields (bug_type, line, description, and filename) as listed in the prompt. 
The 'bug_type' field content generated by the model shows a strong correlation with the 'description' field, demonstrating the model's ability to reason with sufficient information in the 'description' field.
The 'line' field content also shows good results as the model is able to detect which line the bug comes from. Next, the 'description' also achieves good results as it can summarize core issues from the field. 
On the other hand, the 'filename' content is poor in quality. The model isn't able to detect a coherent filename from the information given. 
All in all, the results show the model's good ability to reason and detect bugs from given information, with minor defects in understanding the filename. 
It is important to note that the model is considered to be a Small Language Model (SLM) due to its small parameter size, and better results may be achieved using models with bigger parameters in future experiments.
